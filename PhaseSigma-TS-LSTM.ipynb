{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. Import Libraries\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. Dataset Definition\n",
    "# ============================================================\n",
    "class InSARDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for InSAR time series.\n",
    "\n",
    "    Args:\n",
    "        data (numpy.ndarray): InSAR cube, shape (H, W, T).\n",
    "        dates (list[str]): List of interferogram intervals, e.g. [\"20150815_20150827\", ...].\n",
    "        window_size (int): Temporal window size. Default: 20.\n",
    "        is_prediction (bool): If True, builds dataset for forecasting the next step.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, dates, window_size=20, is_prediction=False):\n",
    "        self.data = data\n",
    "        self.height, self.width, self.time_steps = data.shape\n",
    "        self.window_size = window_size\n",
    "        self.is_prediction = is_prediction\n",
    "\n",
    "        # ---- Extract temporal features ----\n",
    "        self.time_features = []\n",
    "        for date_str in dates:\n",
    "            start_date, end_date = date_str.split('_')\n",
    "            start = datetime.datetime.strptime(start_date, '%Y%m%d')\n",
    "            end = datetime.datetime.strptime(end_date, '%Y%m%d')\n",
    "\n",
    "            year_sin = np.sin(2 * np.pi * start.year / 2100)\n",
    "            year_cos = np.cos(2 * np.pi * start.year / 2100)\n",
    "            month_sin = np.sin(2 * np.pi * start.month / 12)\n",
    "            month_cos = np.cos(2 * np.pi * start.month / 12)\n",
    "            day_sin = np.sin(2 * np.pi * start.day / 31)\n",
    "            day_cos = np.cos(2 * np.pi * start.day / 31)\n",
    "            interval = (end - start).days\n",
    "\n",
    "            self.time_features.append([year_sin, year_cos, month_sin, month_cos,\n",
    "                                       day_sin, day_cos, interval])\n",
    "        self.time_features = np.array(self.time_features)\n",
    "\n",
    "        # ---- Normalize each pixel individually ----\n",
    "        self.scalers = {}\n",
    "        self.scaled_data = np.zeros_like(self.data, dtype=np.float32)\n",
    "\n",
    "        for i in range(self.height):\n",
    "            for j in range(self.width):\n",
    "                pixel_ts = self.data[i, j, :]\n",
    "                scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "                self.scaled_data[i, j, :] = scaler.fit_transform(pixel_ts.reshape(-1, 1)).flatten()\n",
    "                self.scalers[(i, j)] = scaler\n",
    "\n",
    "        # ---- Build sample indices ----\n",
    "        self.samples = [(i, j) for i in range(self.height) for j in range(self.width)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i, j = self.samples[idx]\n",
    "        pixel_ts = self.scaled_data[i, j, :]\n",
    "\n",
    "        if not self.is_prediction:  # Training\n",
    "            x = pixel_ts[:-1]  # first T-1 steps\n",
    "            y = pixel_ts[-1]   # last step\n",
    "            time_feat = self.time_features[:-1]\n",
    "            target_time_feat = self.time_features[-1]\n",
    "        else:  # Prediction\n",
    "            x = pixel_ts\n",
    "            y = 0.0  # placeholder\n",
    "            time_feat = self.time_features[:self.time_steps]\n",
    "            target_time_feat = self.time_features[-1]\n",
    "\n",
    "        return {\n",
    "            'pixel_coords': torch.tensor([i, j]),\n",
    "            'x': torch.tensor(x, dtype=torch.float32),\n",
    "            'time_features': torch.tensor(time_feat, dtype=torch.float32),\n",
    "            'target_time_features': torch.tensor(target_time_feat, dtype=torch.float32),\n",
    "            'y': torch.tensor(y, dtype=torch.float32)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. LSTM Model\n",
    "# ============================================================\n",
    "class InSARLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=64, num_layers=2, dropout=0.1, time_feat_dim=7):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.input_embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.time_embedding = nn.Linear(time_feat_dim, hidden_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        self.target_time_proj = nn.Linear(time_feat_dim, hidden_dim)\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, src, time_features, target_time_features):\n",
    "        batch_size = src.size(0)\n",
    "        src = src.unsqueeze(-1)  # [B, T, 1]\n",
    "        src = self.input_embedding(src)  # [B, T, H]\n",
    "        time_embed = self.time_embedding(time_features)  # [B, T, H]\n",
    "\n",
    "        combined_input = src + time_embed\n",
    "        lstm_out, (h_n, c_n) = self.lstm(combined_input)\n",
    "        seq_repr = h_n[-1]  # last hidden state\n",
    "\n",
    "        target_time_embed = self.target_time_proj(target_time_features)\n",
    "        combined = torch.cat([seq_repr, target_time_embed], dim=-1)\n",
    "\n",
    "        output = self.output_layer(combined)\n",
    "        return output.squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. Training and Prediction Utilities\n",
    "# ============================================================\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50, device='cuda'):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            x = batch['x'].to(device)\n",
    "            time_features = batch['time_features'].to(device)\n",
    "            target_time_features = batch['target_time_features'].to(device)\n",
    "            y = batch['y'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x, time_features, target_time_features)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x = batch['x'].to(device)\n",
    "                time_features = batch['time_features'].to(device)\n",
    "                target_time_features = batch['target_time_features'].to(device)\n",
    "                y = batch['y'].to(device)\n",
    "\n",
    "                outputs = model(x, time_features, target_time_features)\n",
    "                loss = criterion(outputs, y)\n",
    "                val_loss += loss.item() * x.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_future(model, dataset, device='cuda'):\n",
    "    model.eval()\n",
    "    predictions = np.zeros((dataset.height, dataset.width))\n",
    "    dataloader = DataLoader(dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            coords = batch['pixel_coords'].numpy()\n",
    "            x = batch['x'].to(device)\n",
    "            time_features = batch['time_features'].to(device)\n",
    "            target_time_features = batch['target_time_features'].to(device)\n",
    "\n",
    "            outputs = model(x, time_features, target_time_features)\n",
    "            for i in range(len(coords)):\n",
    "                pixel_i, pixel_j = coords[i]\n",
    "                scaler = dataset.scalers[(pixel_i, pixel_j)]\n",
    "                predictions[pixel_i, pixel_j] = scaler.inverse_transform(\n",
    "                    outputs[i].cpu().numpy().reshape(-1, 1))[0, 0]\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. Example Usage\n",
    "# ============================================================\n",
    "\n",
    "# ---- Device ----\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ============================================================\n",
    "# Load Data and Dates\n",
    "# ============================================================\n",
    "\n",
    "# ---- Data ----\n",
    "# data_path should point to your InSAR data file (.npy format).\n",
    "# The .npy file must contain a 3D NumPy array of shape (H, W, T):\n",
    "#   H: image height (number of pixels in vertical dimension)\n",
    "#   W: image width  (number of pixels in horizontal dimension)\n",
    "#   T: number of temporal observations (e.g., 20)\n",
    "#\n",
    "# Each element data[i, j, t] represents the displacement (or wrapped phase, etc.)\n",
    "# for pixel (i, j) at time index t.\n",
    "#\n",
    "# Example:\n",
    "# data_path = \"/your/path/to/data.npy\"\n",
    "# data = np.load(data_path)\n",
    "\n",
    "data_path = \"/your/path/to/insar_data.npy\"   # <-- replace with your file path\n",
    "data = np.load(data_path)\n",
    "print(f\"Data shape: {data.shape}\")   # should be (H, W, T)\n",
    "\n",
    "# ---- Dates ----\n",
    "# `dates` must be a list of acquisition intervals in the form \"YYYYMMDD_YYYYMMDD\".\n",
    "# Each string represents the start and end acquisition dates of an interferogram.\n",
    "#\n",
    "# Example:\n",
    "# dates = [\"20150815_20150827\", \"20150827_20150920\", ... ]\n",
    "#\n",
    "# The length of dates should match the temporal dimension T of your data array.\n",
    "\n",
    "dates = [...]  # <-- replace with your list of interferogram date intervals\n",
    "\n",
    "# ---- Dataset ----\n",
    "full_dataset = InSARDataset(data, dates)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# ---- Model ----\n",
    "model = InSARLSTM(input_dim=1, hidden_dim=64, num_layers=2, dropout=0.1, time_feat_dim=7)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ---- Train ----\n",
    "model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=15, device=device)\n",
    "\n",
    "# ---- Load Best Model ----\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# ---- Predict ----\n",
    "next_date = \"20160821_20160902\"\n",
    "all_dates = dates + [next_date]\n",
    "predict_dataset = InSARDataset(data, all_dates, is_prediction=True)\n",
    "\n",
    "future_predictions = predict_future(model, predict_dataset, device)\n",
    "np.save('future_predictions.npy', future_predictions)\n",
    "\n",
    "# ---- Visualization ----\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(data[:, :, -1], cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('Last Available Time Point')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(future_predictions, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('Predicted Future Time Point (LSTM)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6. Save Dataset for Reuse\n",
    "# ============================================================\n",
    "with open('predict_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(predict_dataset, f)\n",
    "\n",
    "print(\"Prediction dataset saved as 'predict_dataset.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. Import Libraries\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. Function: Normalized Difference Calculation\n",
    "# ============================================================\n",
    "def calculate_difference(interferogram1, interferogram2, chunk_size=1024):\n",
    "    \"\"\"\n",
    "    Compute the normalized difference between two interferograms\n",
    "    with block-wise processing to reduce memory usage.\n",
    "    \n",
    "    Args:\n",
    "        interferogram1 (np.ndarray): First interferogram (2D array).\n",
    "        interferogram2 (np.ndarray): Second interferogram (2D array).\n",
    "        chunk_size (int): Block size for processing to avoid memory overflow.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Difference map (float32), with NaN for invalid pixels.\n",
    "    \"\"\"\n",
    "    if interferogram1.shape != interferogram2.shape:\n",
    "        raise ValueError(\"Both interferograms must have the same shape.\")\n",
    "    \n",
    "    rows, cols = interferogram1.shape\n",
    "    difference = np.zeros((rows, cols), dtype=np.float32)\n",
    "\n",
    "    chunk_rows = max(1, min(chunk_size, rows))\n",
    "    chunk_cols = max(1, min(chunk_size, cols))\n",
    "\n",
    "    for i in range(0, rows, chunk_rows):\n",
    "        for j in range(0, cols, chunk_cols):\n",
    "            end_i = min(i + chunk_rows, rows)\n",
    "            end_j = min(j + chunk_cols, cols)\n",
    "\n",
    "            if end_i <= i or end_j <= j:\n",
    "                continue\n",
    "\n",
    "            chunk1 = interferogram1[i:end_i, j:end_j]\n",
    "            chunk2 = interferogram2[i:end_i, j:end_j]\n",
    "\n",
    "            epsilon = 1e-8\n",
    "            denominator = chunk1 + chunk2 + epsilon\n",
    "            valid_mask = denominator != 0\n",
    "\n",
    "            diff_chunk = np.full_like(chunk1, np.nan, dtype=np.float32)\n",
    "            diff_chunk[valid_mask] = (chunk1[valid_mask] - chunk2[valid_mask]) / denominator[valid_mask]\n",
    "\n",
    "            difference[i:end_i, j:end_j] = diff_chunk\n",
    "\n",
    "    mask = np.isnan(interferogram1) | np.isnan(interferogram2) | (interferogram1 == 0) | (interferogram2 == 0)\n",
    "    difference[mask] = np.nan\n",
    "\n",
    "    return difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. Input Data Description\n",
    "# ============================================================\n",
    "\n",
    "# Input files:\n",
    "# - assumed co-disaster value (predicted by the LSTM model)\n",
    "# - geninue co-disaster value (observed data)\n",
    "\n",
    "# Both should be saved as `.npy` files with shape (H, W),\n",
    "# where each element represents the interferometric phase\n",
    "# at pixel (i, j).\n",
    "\n",
    "# Example file structure:\n",
    "# base_dir/\n",
    "#   ├── geninue.npy     (geninue co-disaster value)\n",
    "#   ├── predicted.npy (predicted co-disaster value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. Load Input Data\n",
    "# ============================================================\n",
    "\n",
    "base_dir = \"/your/path/to/\"   # <-- Replace with your path\n",
    "\n",
    "file1_path = os.path.join(base_dir, \"geninue.npy\")   # ground truth\n",
    "file2_path = os.path.join(base_dir, \"predicted.npy\")  # model prediction\n",
    "\n",
    "ifg_true = np.load(file1_path)\n",
    "ifg_pred = np.load(file2_path)\n",
    "\n",
    "print(f\"Loaded file: {file1_path}, shape: {ifg_true.shape}\")\n",
    "print(f\"Loaded file: {file2_path}, shape: {ifg_pred.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. Compute Normalized Difference Score\n",
    "# ============================================================\n",
    "\n",
    "phase_score = calculate_difference(ifg_true, ifg_pred, chunk_size=512)\n",
    "\n",
    "# Apply masking for NaN/zeros\n",
    "phase_score = np.where(np.isnan(ifg_true), np.nan,\n",
    "                      np.where(ifg_true == 0, 0, phase_score))\n",
    "phase_score = np.where(np.isnan(ifg_pred), np.nan,\n",
    "                      np.where(ifg_pred == 0, 0, phase_score))\n",
    "\n",
    "print(\"Score map computed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6. Save Results\n",
    "# ============================================================\n",
    "\n",
    "output_filename = \"score.npy\"\n",
    "output_path = os.path.join(base_dir, output_filename)\n",
    "\n",
    "np.save(output_path, phase_score)\n",
    "print(f\"Result saved as {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7. Visualization Example\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(ifg_true, cmap=\"viridis\")\n",
    "plt.title(\"Geninue Co-Disaster Value\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(ifg_pred, cmap=\"viridis\")\n",
    "plt.title(\"Predicted Co-Disaster Value\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(phase_score, cmap=\"bwr\", vmin=-1, vmax=1)\n",
    "plt.title(\"Normalized Difference Score\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
